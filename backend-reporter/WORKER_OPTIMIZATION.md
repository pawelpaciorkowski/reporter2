# Worker Restart Optimization

## Problem
Oryginalny `restart_workers.py` jest bardzo wolny gdy masz duÅ¼o laboratoriÃ³w (~70+), poniewaÅ¼:

1. **Sekwencyjnie** zabija kaÅ¼dy worker (jeden po drugim) 
2. **Sekwencyjnie** startuje kaÅ¼dy worker (jeden po drugim)
3. **Brak timeout-Ã³w** - zawieszone workery mogÄ… blokowaÄ‡ proces w nieskoÅ„czonoÅ›Ä‡
4. **Brak force kill** - jeÅ›li graceful quit nie dziaÅ‚a, proces siÄ™ zawiesza

## RozwiÄ…zania

### ğŸš€ Szybkie rozwiÄ…zania (wyprÃ³buj w kolejnoÅ›ci):

#### 1. Najszybsze - Bash script + Python
```bash
cd reporter/backend-reporter
./kill_workers_fast.sh      # Zabija wszystkie workery rÃ³wnolegle
python restart_workers.py   # Startuje workery oryginalnÄ… metodÄ…
```

#### 2. Zoptymalizowana wersja Python (zalecane)
```bash
cd reporter/backend-reporter
python restart_workers_fast.py  # Zabija i startuje wszystko rÃ³wnolegle
```

#### 3. Tylko szybkie startowanie
```bash
cd reporter/backend-reporter
python start_workers_fast.py    # Startuje workery bez killowania istniejÄ…cych
```

#### 4. Jednorazowe rozwiÄ…zanie
```bash
pkill -f "rq worker.*repworker"  # Force kill wszystkich workerÃ³w
screen -wipe                     # Cleanup screen sessions  
python restart_workers.py       # Startuj normalnie
```

## Pliki

- `restart_workers_fast.py` - Zoptymalizowana wersja z rÃ³wnolegÅ‚ym kill+start
- `start_workers_fast.py` - Tylko rÃ³wnolegÅ‚e startowanie workerÃ³w
- `kill_workers_fast.sh` - Szybkie bash-owe killowanie workerÃ³w  
- `benchmark_restart.py` - PorÃ³wnywanie czasÃ³w wykonania

## RÃ³Å¼nice w wydajnoÅ›ci

### Oryginalna metoda:
- â±ï¸ **70+ workerÃ³w** = **5-15 minut** (sekwencyjnie)
- ğŸ“Š ~0.2-0.5 worker/sekundÄ™
- âŒ MoÅ¼e siÄ™ zawiesiÄ‡ na zombie processes

### Zoptymalizowana metoda:  
- â±ï¸ **70+ workerÃ³w** = **30-60 sekund** (rÃ³wnolegle)
- ğŸ“Š ~2-5 workerÃ³w/sekundÄ™  
- âœ… Timeout-y i force kill zapobiegajÄ… zawieszeniu

### **Przyspieszenie: 10-20x szybsze!**

## Testowanie

```bash
# Test zoptymalizowanej wersji
python benchmark_restart.py

# Test oryginalnej wersji (do porÃ³wnania)  
python benchmark_restart.py --test-old
```

## Opcje

Wszystkie skrypty obsÅ‚ugujÄ…:
- `--clear-queues` - WyczyÅ›Ä‡ kolejki przed startem workerÃ³w

## SzczegÃ³Å‚y implementacji

### RÃ³wnolegÅ‚e killowanie:
- **ThreadPoolExecutor** z max 20 wÄ…tkami
- **Timeout 5s** na graceful quit
- **Force kill** jeÅ›li graceful quit nie dziaÅ‚a
- **Fallback na kill -9** dla zombie processes

### RÃ³wnolegÅ‚e startowanie:
- **ThreadPoolExecutor** z max 30 wÄ…tkami
- **Grupowanie laboratoriÃ³w** po 4 w multiworkerach
- **Progress monitoring** - pokazuje postÄ™p co 10 workerÃ³w
- **Error handling** - kontynuuje mimo bÅ‚Ä™dÃ³w

### BezpieczeÅ„stwo:
- **Timeout-y** na wszystkich operacjach
- **Exception handling** 
- **Graceful degradation** jeÅ›li nie moÅ¼na zabiÄ‡ niektÃ³rych workerÃ³w

## Dlaczego u Ciebie byÅ‚o wolno?

1. **DuÅ¼o laboratoriÃ³w** - masz ~70+ vs prawdopodobnie kilka/kilkanaÅ›cie u kolegi
2. **Sekwencyjne operacje** - kaÅ¼dy worker obsÅ‚ugiwany osobno
3. **Brak timeout-Ã³w** - zawieszone workery blokujÄ… caÅ‚y proces
4. **RAM nie ma znaczenia** - problem jest w I/O i liczbie procesÃ³w, nie w pamiÄ™ci

## Backup

Oryginalny `restart_workers.py` pozostaje niezmieniony - moÅ¼esz wrÃ³ciÄ‡ do niego w kaÅ¼dej chwili. 